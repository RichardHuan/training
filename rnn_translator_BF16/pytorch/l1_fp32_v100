STARTING TIMING RUN AT 2020-02-06 02:39:10 AM
running benchmark
:::MLPv0.5.0 gnmt 1580956755.734841108 (train.py:180) run_start
Namespace(batch_size=128, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, dist_url='tcp://localhost:23456', epochs=8, eval_batch_size=32, grad_clip=5.0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, math='fp32', max_length_train=50, max_length_val=150, max_size=None, min_length_train=0, min_length_val=0, model_config="{'hidden_size': 1024,'num_layers': 4,                         'dropout': 0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'Adam', 'lr': 5e-4}", print_freq=10, rank=0, results_dir='../results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, seed=1, smoothing=0.1, start_epoch=0, target_bleu=21.8, workers=0, world_size=1)
:::MLPv0.5.0 gnmt 1580956755.738347054 (train.py:187) run_set_random_seed
:::MLPv0.5.0 gnmt 1580956757.789253235 (train.py:217) preproc_tokenize_training
:::MLPv0.5.0 gnmt 1580956757.789819241 (train.py:219) train_hp_max_sequence_length: 50
:::MLPv0.5.0 gnmt 1580956889.734002113 (train.py:231) preproc_num_train_examples: 3498161
:::MLPv0.5.0 gnmt 1580956890.600489616 (train.py:241) preproc_tokenize_eval
:::MLPv0.5.0 gnmt 1580956890.711297274 (train.py:252) preproc_num_eval_examples: 3003
:::MLPv0.5.0 gnmt 1580956890.711617947 (train.py:255) preproc_vocab_size: 32317
:::MLPv0.5.0 gnmt 1580956890.712303638 (seq2seq/models/gnmt.py:19) model_hp_num_layers: 4
:::MLPv0.5.0 gnmt 1580956890.712590694 (seq2seq/models/gnmt.py:21) model_hp_hidden_size: 1024
:::MLPv0.5.0 gnmt 1580956890.712858438 (seq2seq/models/gnmt.py:23) model_hp_dropout: 0.2
:::MLPv0.5.0 gnmt 1580956892.284574986 (train.py:170) model_hp_loss_fn: "Cross Entropy with label smoothing"
:::MLPv0.5.0 gnmt 1580956892.284937620 (train.py:172) model_hp_loss_smoothing: 0.1
:::MLPv0.5.0 gnmt 1580956898.975090981 (seq2seq/train/trainer.py:71) opt_name: "Adam"
:::MLPv0.5.0 gnmt 1580956898.975467443 (seq2seq/train/trainer.py:73) opt_learning_rate: 0.0005
:::MLPv0.5.0 gnmt 1580956898.975745440 (seq2seq/train/trainer.py:75) opt_hp_Adam_beta1: 0.9
:::MLPv0.5.0 gnmt 1580956898.976013899 (seq2seq/train/trainer.py:77) opt_hp_Adam_beta2: 0.999
:::MLPv0.5.0 gnmt 1580956898.976303577 (seq2seq/train/trainer.py:79) opt_hp_Adam_epsilon: 1e-08
:::MLPv0.5.0 gnmt 1580956898.976864815 (seq2seq/inference/beam_search.py:30) eval_hp_beam_size: 5
:::MLPv0.5.0 gnmt 1580956898.977182388 (seq2seq/inference/beam_search.py:32) eval_hp_max_sequence_length: 150
:::MLPv0.5.0 gnmt 1580956898.977480412 (seq2seq/inference/beam_search.py:34) eval_hp_length_normalization_constant: 5.0
:::MLPv0.5.0 gnmt 1580956898.977772236 (seq2seq/inference/beam_search.py:36) eval_hp_length_normalization_factor: 0.6
:::MLPv0.5.0 gnmt 1580956898.978061914 (seq2seq/inference/beam_search.py:38) eval_hp_coverage_penalty_factor: 0.1
:::MLPv0.5.0 gnmt 1580956898.979927063 (train.py:321) input_batch_size: 128
:::MLPv0.5.0 gnmt 1580956898.980203867 (train.py:323) input_size: 3498112
:::MLPv0.5.0 gnmt 1580956898.980501413 (train.py:341) eval_size: 3003
:::MLPv0.5.0 gnmt 1580956898.980745316 (train.py:345) train_loop
:::MLPv0.5.0 gnmt 1580956898.980991125 (train.py:348) train_epoch: 0
:::MLPv0.5.0 gnmt 1580956899.570185423 (seq2seq/data/sampler.py:31) input_order
:::MLPv0.5.0 gnmt 1580966382.375287771 (train.py:366) train_checkpoint
:::MLPv0.5.0 gnmt 1580966384.953703403 (train.py:383) eval_start: 0
:::MLPv0.5.0 gnmt 1580966427.379871607 (train.py:467) eval_accuracy: {"epoch": 0, "value": 19.43}
:::MLPv0.5.0 gnmt 1580966427.380408764 (train.py:469) eval_target: 21.8
:::MLPv0.5.0 gnmt 1580966427.380813599 (train.py:470) eval_stop
:::MLPv0.5.0 gnmt 1580966427.381501436 (train.py:348) train_epoch: 1
:::MLPv0.5.0 gnmt 1580966427.865983963 (seq2seq/data/sampler.py:31) input_order
:::MLPv0.5.0 gnmt 1580975922.026838541 (train.py:366) train_checkpoint
:::MLPv0.5.0 gnmt 1580975936.176302433 (train.py:383) eval_start: 1
:::MLPv0.5.0 gnmt 1580975975.210936785 (train.py:467) eval_accuracy: {"epoch": 1, "value": 20.95}
:::MLPv0.5.0 gnmt 1580975975.211287260 (train.py:469) eval_target: 21.8
:::MLPv0.5.0 gnmt 1580975975.211567163 (train.py:470) eval_stop
:::MLPv0.5.0 gnmt 1580975975.212027073 (train.py:348) train_epoch: 2
:::MLPv0.5.0 gnmt 1580975975.708797455 (seq2seq/data/sampler.py:31) input_order
:::MLPv0.5.0 gnmt 1580985463.144563437 (train.py:366) train_checkpoint
:::MLPv0.5.0 gnmt 1580985494.324169397 (train.py:383) eval_start: 2
:::MLPv0.5.0 gnmt 1580985536.810574055 (train.py:467) eval_accuracy: {"epoch": 2, "value": 21.79}
:::MLPv0.5.0 gnmt 1580985536.811023474 (train.py:469) eval_target: 21.8
:::MLPv0.5.0 gnmt 1580985536.811373472 (train.py:470) eval_stop
:::MLPv0.5.0 gnmt 1580985536.811946392 (train.py:348) train_epoch: 3
:::MLPv0.5.0 gnmt 1580985537.317596674 (seq2seq/data/sampler.py:31) input_order
:::MLPv0.5.0 gnmt 1580995025.150437355 (train.py:366) train_checkpoint
:::MLPv0.5.0 gnmt 1580995048.215778828 (train.py:383) eval_start: 3
:::MLPv0.5.0 gnmt 1580995089.996963024 (train.py:467) eval_accuracy: {"epoch": 3, "value": 22.05}
:::MLPv0.5.0 gnmt 1580995089.997407913 (train.py:469) eval_target: 21.8
:::MLPv0.5.0 gnmt 1580995089.997754812 (train.py:470) eval_stop
:::MLPv0.5.0 gnmt 1580995089.998325825 (train.py:480) run_stop: {"success": true}
:::MLPv0.5.0 gnmt 1580995089.998679638 (train.py:481) run_final
ENDING TIMING RUN AT 2020-02-06 01:18:22 PM
RESULT,RNN_TRANSLATOR,1,38352,,2020-02-06 02:39:10 AM
